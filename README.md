# Building an ETL pipeline with Apache Airflow, a data warehouse in AWS Redshift and a Power BI dashboard

<p align="justify">
  
> Have you heard phrases like **Hungry? You're in the right place** or **Request a trip, hop in, and relax.** ? :roll_eyes: Both phrases are very common in our daily lives, they represent the emblems of the two most important businesses with <a href="https://qz.com/1889602/uber-q2-2020-earnings-eats-is-now-bigger-than-rides/"> millionaire revenues </a> from UBER. **Have you ever thought about how much money you spend on these services?** The goal of this project is to track the expenses of <a href="https://www.uber.com/">Uber Rides</a> and <a  href="https://www.ubereats.com/">Uber Eats</a> through a Data Engineering processes using technologies such as <a href="https://airflow.apache.org/">Apache Airflow</a>, <a href="https://aws.amazon.com/es/redshift/">AWS Redshift</a> and <a href="https://powerbi.microsoft.com/es-es/">Power BI</a>. Keep reading this article, I will show you a quick way to automate the tracking of your expenses for these Uber services following an easy and fast data engineering process.

</p>

## What are the data sources?
## Data modelling
## Infrastructure as Code in AWS
## Building an ETL pipeline in Apache Airflow
## Building reports with Power BI 





